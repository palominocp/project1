{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: In this part we start with MME analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d88b1b3a12b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"your Key\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import gmaps\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "api_key=\"your Key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MME:\n",
    "1. ATTACHED UE\n",
    "2. BEARERS\n",
    "3. AVECPUUSAGE\n",
    "Description: This counter indicates the average CPU utilization in the current interval.\n",
    "Unit: %\n",
    "Range: 0-100\n",
    "4. PEAKCPUUSAGE\n",
    "Description: This counter indicates the peak CPU utilization in the current interval.\n",
    "Unit: %\n",
    "Range: 0-100\n",
    "5. MEMUSEDSIZE\n",
    "Description: This counter identifies the amount of memory (in MB) used in the current\n",
    "reporting interval.\n",
    "6. MEMAVAILABLESIZE\n",
    "Description: This counter identifies the amount of memory (in MB) available in the current\n",
    "reporting interval.\n",
    "\n",
    "SAEGW:\n",
    "1. Throuhgput\n",
    "2. Maximum number of bearers\n",
    "3. MAXCPUUTILIZATION\n",
    "Max CPU utilization per CP-ISA card or per MG-VM in the end of the polling interval. For CMG fast-path cores are excluded from calculations\n",
    "4. MAXMEMORYUTILIZATION\n",
    "Max Memory utilization per CP-ISA card or per MG-VM at the end of polling interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading from XLX files to PD. Data Frame\n",
    "mme = pd.read_excel('Resources/mme.xlsx')\n",
    "mme_kpi = pd.read_excel('Resources/mme_cpu_mem.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first ten records of MME File\n",
    "mme.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first ten records of MME_KPI File\n",
    "mme_kpi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group KPI Files by Location MME and date day\n",
    "mme_kpi_grp = mme_kpi.groupby([\"LOCATION\",\"MME\",\"DATEDAY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Mean of main KPI's\n",
    "mme_kpi_grp[[\"AVECPUUSAGE\",\"PEAKCPUUSAGE\",\"PERIOD_DURATION\"]].mean()\n",
    "m_k = mme_kpi_grp[[\"AVECPUUSAGE\",\"PEAKCPUUSAGE\",\"PERIOD_DURATION\"]].mean()\n",
    "m_k.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Date and Hour form Period Start Time .\n",
    "mme[\"DATEDAY\"] = mme[\"PERIOD_START_TIME\"].astype(str).str[:10]\n",
    "mme[\"TIME\"] = mme[\"PERIOD_START_TIME\"].astype(str).str[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by \"LOCATION\",\"MME\",\"DATEDAY\",\"TIME\"])to get mean of Attacehd UE and EPS Bearers\n",
    "m_g = mme.groupby([\"LOCATION\",\"MME\",\"DATEDAY\",\"TIME\"])[[\"Attached UE\",\"EPS Bearers\"]].mean()\n",
    "m_g.reset_index(inplace=True)\n",
    "m_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mme_df = pd.merge(m_g, m_k,  how='inner', on=[\"MME\",\"DATEDAY\"])\n",
    "# Merge KPI + Attached US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mme_df[\"LOCATION_y\"]\n",
    "#Delete additional column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "mme_df =mme_df.rename(columns={\"LOCATION_x\":\"city\"})\n",
    "mme_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify Empty values \n",
    "mme_df[pd.isnull(mme_df).any(axis=1)]\n",
    "#None Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create Box Plots\n",
    "# Example outlier plot of reaction times\n",
    "def box_t(data,title,ylabel):\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_title(f'{title}')\n",
    "    ax1.set_ylabel(f'{ylabel}')\n",
    "    ax1.boxplot(data)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot for KPI Attached UE\n",
    "#mme_df[\"Attached UE\"]\n",
    "mmes = mme_df[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    box_t(mme_df[mme_df[\"MME\"] == x][\"Attached UE\"],f'Box plot for : {x}',\"Attached UE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "#Create violin plot to observe the desity and distribution per day\n",
    "\n",
    "mmes = mme_df[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    plt.figure()\n",
    "    ax = sns.violinplot(x=mme_df[mme_df[\"MME\"] == x][\"DATEDAY\"].astype(str).str[8:10], y=mme_df[mme_df[\"MME\"] == x][\"Attached UE\"])\n",
    "    plt.title(x)\n",
    "\n",
    "for x in mmes:\n",
    "    plt.figure()\n",
    "    ax = sns.violinplot(x=mme_df[mme_df[\"MME\"] == x][\"DATEDAY\"].astype(str).str[8:10], y=mme_df[mme_df[\"MME\"] == x][\"EPS Bearers\"])\n",
    "    plt.title(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create scatter plots\n",
    "\n",
    "def scatter_p(kind,x,y,xlabel,ylabel,title,data):\n",
    "    scatter = data.plot(kind=kind,x=x,y=y,c='b')\n",
    "    scatter.set_xlabel(x)\n",
    "    scatter.set_ylabel(y)\n",
    "    scatter.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship with Attacehd UE and and Average CPU usage for each MME\n",
    "#Not able to identify corealtion\n",
    "mmes = mme_df[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    \n",
    "    scatter_p(\"scatter\",\"Attached UE\",\"AVECPUUSAGE\",\"Attached UE\",\"AVECPUUSAGE\",x,mme_df[mme_df[\"MME\"] == x])\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship with Attacehd UE and  EPS Bearers usage for each MME\n",
    "#Linnear corealtion identified\n",
    "mmes = mme_df[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    \n",
    "    scatter_p(\"scatter\",\"Attached UE\",\"EPS Bearers\",\"Attached UE\",\"EPS Bearers\",x,mme_df[mme_df[\"MME\"] == x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm relation with a regression nalysis\n",
    "from scipy.stats import linregress\n",
    "for mm in mmes:\n",
    "    x_values = mme_df[mme_df[\"MME\"] == mm][\"Attached UE\"].values\n",
    "    y_values = mme_df[mme_df[\"MME\"] == mm][\"EPS Bearers\"].values\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "    regress_values = x_values * slope + intercept\n",
    "    line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "    plt.scatter(x_values,y_values)\n",
    "    plt.plot(x_values,regress_values,\"r-\")\n",
    "    plt.annotate(line_eq,(6,10),fontsize=15,color=\"red\")\n",
    "    plt.xlabel(\"Attached UE-\" + mm)\n",
    "    plt.ylabel('EPS Bearers' )\n",
    "    print(f\"The r-squared for {mm} is: {rvalue**2}\")\n",
    "    plt.annotate(line_eq,(mme_df[mme_df[\"MME\"] == mm][\"EPS Bearers\"].min(),mme_df[mme_df[\"MME\"] == mm][\"Attached UE\"].min()),fontsize=15,color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression model and compare train vs testing\n",
    "\n",
    "mmes = mme_df[\"MME\"].unique()\n",
    "for mm in mmes:\n",
    "    regressor = LinearRegression()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(mme_df[mme_df[\"MME\"] == mm][\"Attached UE\"].values.reshape(-1,1), mme_df[mme_df[\"MME\"] == mm][\"EPS Bearers\"].values.reshape(-1,1), test_size=0.2, random_state=0)\n",
    "    \n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict =regressor.predict(X_test)\n",
    "\n",
    "    \n",
    "    plt.scatter(X_test, y_test,  color='gray')\n",
    "    plt.xlabel(\"Attached UE\" + mm)\n",
    "    plt.ylabel(\"EPS Bearers\")\n",
    "    \n",
    "    plt.plot(X_test, y_predict, color='red', linewidth=2)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#bar = plt.subplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data to get Lat and Lng from Google\n",
    "cities = mme_df[\"city\"].unique()\n",
    "mmes = mme_df[\"MME\"].unique()\n",
    "cities\n",
    "\n",
    "lat=[]\n",
    "lng=[]\n",
    "maxcap = dict()\n",
    "#Get MAx values to compare capacity - Data provided by expert\n",
    "maxcap = {'MME-180000-MME01-APODACA':1485457, 'MME-180000-MME02-APODACA':1485457,\n",
    "       'MME-250000-MME01-HERMOSILLO':200464, 'MME-300000-MME01-MERIDA':135838,\n",
    "       'MME-140000-MME01-TULTITLAN':2380000, 'MME-140000-MME02-TULTITLAN':2380000}\n",
    "\n",
    "#Get Lat and lng for all cities , only the required calls to Google api\n",
    "for city in cities:\n",
    "    url=f\"https://maps.googleapis.com/maps/api/geocode/json?address={city}&key={api_key}\"\n",
    "    response=requests.get(url).json()\n",
    "    lat.append(response[\"results\"][0][\"geometry\"][\"location\"][\"lat\"])\n",
    "    lng.append(response[\"results\"][0][\"geometry\"][\"location\"][\"lng\"])\n",
    "    mme_df.loc[(mme_df[\"city\"] == city),'lat']=response[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "    mme_df.loc[(mme_df[\"city\"] == city),'lng']=response[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "\n",
    "\n",
    "#Calculate Cpapcity percentage     \n",
    "for mm in mmes:\n",
    "    \n",
    "    mme_df.loc[(mme_df[\"MME\"] == mm),'maxcap']=maxcap[mm]\n",
    "    #mme_df.loc[(mme_df[\"MME\"] == mm),'capperc']=maxcap[mm]\n",
    "\n",
    "mme_df[\"capperc\"] = (mme_df[\"Attached UE\"] / mme_df[\"maxcap\"] )\n",
    "mme_df.style.format({'capperc': \"{:.2%}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_data = pd.DataFrame(zip(cities,lat,lng),columns=['city','lat','lng'])\n",
    "#cities_data    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m=mme_df.groupby([\"MME\",\"city\",\"lat\",\"lng\"]).agg([\"mean\",\"sum\",\"max\",\"min\"])\n",
    "cities_data = m.reset_index()\n",
    "cities_data\n",
    "cities_data[\"capperc\"]\n",
    "\n",
    "##MME , Columnas por dia, Valor Maximo y pocentaje utilizado  (Max/Attached) Color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat map attached cities\n",
    "fig = gmaps.figure(center=(20.0, -100.0), zoom_level=2.8)\n",
    "\n",
    "\n",
    "heat_layer = gmaps.heatmap_layer(locations=cities_data[[\"lat\",\"lng\"]].astype(float), weights=cities_data[\"Attached UE\"][\"mean\"], \n",
    "                             dissipating=False, max_intensity=100\n",
    "                             ,point_radius = 1)\n",
    "\n",
    "# Add marker layer ontop of heat map\n",
    "\n",
    "\n",
    "sym_layer = gmaps.symbol_layer(\n",
    "    locations=cities_data[[\"lat\",\"lng\"]].astype(float), fill_color='rgba(0, 150, 0, 0.4)',\n",
    "    stroke_color='rgba(0, 0, 150, 0.4)', scale=5,\n",
    "    info_box_content=[f\"City: {row['city']},  Attached UE :{row[['Attached UE','EPS Bearers']]} \" for index,row in cities_data.iterrows()]\n",
    ")\n",
    "fig.add_layer(heat_layer)\n",
    "fig.add_layer(sym_layer)\n",
    "\n",
    "fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create bar plots\n",
    "\n",
    "def bar_p(kind,x,y,xlabel,ylabel,title,data):\n",
    "    scatter = data.plot(kind=kind,x=x,y=y)\n",
    "    scatter.set_xlabel(x)\n",
    "    scatter.set_ylabel(y)\n",
    "    scatter.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the max number of attached users per day\n",
    "m=mme_df.groupby([\"MME\",\"city\",\"DATEDAY\"]).max()\n",
    "m.reset_index(inplace=True)\n",
    "mmes = m[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    \n",
    "    bar_p(\"bar\",\"DATEDAY\",\"Attached UE\",\"Date\",\"Attached UE\",x,m[m[\"MME\"] == x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=mme_df.groupby([\"MME\",\"DATEDAY\"])[\"Attached UE\"].max().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the max number of attached users per hour\n",
    "m=mme_df.groupby([\"MME\",\"city\",\"TIME\"]).max()\n",
    "m.reset_index(inplace=True)\n",
    "mmes = m[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    \n",
    "    bar_p(\"bar\",\"TIME\",\"Attached UE\",\"Date\",\"Attached UE\",x,m[m[\"MME\"] == x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the capacity % number per day\n",
    "m=mme_df.groupby([\"MME\",\"city\",\"DATEDAY\"]).max()\n",
    "m.reset_index(inplace=True)\n",
    "mmes = m[\"MME\"].unique()\n",
    "for x in mmes:\n",
    "    \n",
    "    bar_p(\"bar\",\"DATEDAY\",\"capperc\",\"Date\",\"% Utilizacion\",x,m[m[\"MME\"] == x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get mean of capacity percentage by MME\n",
    "s=m.groupby(\"MME\")[\"capperc\"].max().reset_index()\n",
    "s[\"capperc\"]=s[\"capperc\"]*100\n",
    "s.style.format({'capperc': \"{:.2%}\"},)\n",
    "s.plot(kind=\"bar\",x=\"MME\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Here we start with SAEGW analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set excel paths\n",
    "saegw = \"Resources/saegw.xlsx\"\n",
    "saegw_bearers = \"Resources/saegw_bearers.xlsx\"\n",
    "\n",
    "groupby_saegw = pd.read_excel(saegw).groupby(['dateday','SAEGW'])\n",
    "saegw_df = groupby_saegw.max()\n",
    "saegw_bearers_df = pd.read_excel(saegw_bearers)\n",
    "\n",
    "# merge and clean\n",
    "merge_saegw = pd.merge(saegw_df,saegw_bearers_df, on=[\"dateday\",\"SAEGW\"])\n",
    "merge_saegw_clean = merge_saegw[['dateday', 'SAEGW', 'LOCATION_x', 'Throuhgput', 'Maximum number of bearers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all SAEGW\n",
    "plot_all = merge_saegw_clean.groupby(['SAEGW']).max()\n",
    "plot_all.reset_index(inplace=True)\n",
    "plot_all.plot.bar(x=0,y=3,title= \"All Maximum Throughput\")\n",
    "plt.savefig('All Maximum Throughput')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new tables by location\n",
    "tultitlan = merge_saegw_clean[merge_saegw_clean.LOCATION_x == 'tultitlan']\n",
    "apodaca = merge_saegw_clean[merge_saegw_clean.LOCATION_x == 'apodaca']\n",
    "hermosillo = merge_saegw_clean[merge_saegw_clean.LOCATION_x == 'hermosillo']\n",
    "merida = merge_saegw_clean[merge_saegw_clean.LOCATION_x == 'merida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on tultitlan 1\n",
    "tult_max_saegw = tultitlan.groupby(['SAEGW']).max()\n",
    "tult_max_saegw.reset_index(inplace=True)\n",
    "tult_max_saegw.head(2).plot.bar(x=0,y=3,label=\"Max Throughput\",title='Tultitlan Maximum Throughput 1').set_ylim(0,150000)\n",
    "plt.hlines(32000,-1,2,color='y')\n",
    "plt.hlines(40000,-1,2,color='r')\n",
    "plt.savefig('Tultitlan Maximum Throughput 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on tultitlan 2\n",
    "tult_max_saegw = tultitlan.groupby(['SAEGW']).max()\n",
    "tult_max_saegw.reset_index(inplace=True)\n",
    "tult_max_saegw.tail(2).plot.bar(x=0,y=3,label=\"Max Throughput\",title='Tultitlan Maximum Throughput 2').set_ylim(0,150000)\n",
    "plt.hlines(115200,-1,2,color='y')\n",
    "plt.hlines(144000,-1,2,color='r')\n",
    "plt.savefig('Tultitlan Maximum Throughput 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on apodaca 1\n",
    "apo_max_saegw = apodaca.groupby(['SAEGW']).max()\n",
    "apo_max_saegw.reset_index(inplace=True)\n",
    "apo_max_saegw.head(2).plot.bar(x=0,y=3,label='Max Throughput',title=\"Apodaca Maximum Throughput 1\").set_ylim(0,150000)\n",
    "plt.hlines(32000,-1,2,color='y')\n",
    "plt.hlines(40000,-1,2,color='r')\n",
    "plt.savefig('Apodaca Maximum Throughput 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on apodaca 2\n",
    "apo_max_saegw = apodaca.groupby(['SAEGW']).max()\n",
    "apo_max_saegw.reset_index(inplace=True)\n",
    "apo_max_saegw.tail(1).plot.bar(x=0,y=3,label='Max Throughput',title=\"Apodaca Maximum Throughput 2\").set_ylim(0,150000)\n",
    "plt.hlines(115200,-1,1,color='y')\n",
    "plt.hlines(144000,-1,1,color='r')\n",
    "plt.savefig('Apodaca Maximum Throughput 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on hermosillo\n",
    "her_max_saegw = hermosillo.groupby(['SAEGW']).max()\n",
    "her_max_saegw.reset_index(inplace=True)\n",
    "her_max_saegw.plot.bar(x=0,y=3,label='Max Throughput',title=\"Hermosillo Maximum Throughput\")\n",
    "plt.hlines(10000,-1,4,color='r')\n",
    "plt.hlines(8000,-1,4,color='y')\n",
    "plt.savefig(\"Hermosillo Maximum Throughput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on merida\n",
    "mer_max_saegw = merida.groupby(['SAEGW']).max()\n",
    "mer_max_saegw.reset_index(inplace=True)\n",
    "mer_max_saegw.plot.bar(x=0,y=3,label='Max Throughput',title=\"Merida Maximum Throughput\")\n",
    "plt.hlines(10000,-1,4,color='r')\n",
    "plt.hlines(8000,-1,4,color='y')\n",
    "plt.savefig(\"Merdia Maximum Throughput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start day of the week analysis\n",
    "week_all = merge_saegw_clean.groupby(['dateday']).mean().reset_index()\n",
    "week_all.plot.bar(x=0,y=1,legend=False,title='Average throughput by day of the week')\n",
    "plt.savefig('Week_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of the week analysis Tultitlan\n",
    "tult_week = tultitlan.groupby('dateday').mean().reset_index()\n",
    "tult_week.plot.bar(x=0,y=1,legend=False,title='Tultitlan use by weekday')\n",
    "plt.savefig('Tultitlan_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of the week analysis Apodaca\n",
    "apo_week = apodaca.groupby('dateday').mean().reset_index()\n",
    "apo_week.plot.bar(x=0,y=1,legend=False,title='Apodaca use by weekday')\n",
    "plt.savefig('Apodaca_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of the week analysis Hermosillo\n",
    "her_week = hermosillo.groupby('dateday').mean().reset_index()\n",
    "her_week.plot.bar(x=0,y=1,legend=False,title='Hermosillo use by weekday')\n",
    "plt.savefig('Hermosillo_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of the week analysis Merida\n",
    "mer_week = merida.groupby('dateday').mean().reset_index()\n",
    "mer_week.plot.bar(x=0,y=1,legend=False,title='Merida use by weekday')\n",
    "plt.savefig('Merida_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
